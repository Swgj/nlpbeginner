{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "from Preprocessor import Preprocessor\n",
    "from Train import run_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# def preprocess(inputdir,\n",
    "#                embeddings_file,\n",
    "#                targetdir,\n",
    "#                lowercase=False,\n",
    "#                ignore_punctuation=False,\n",
    "#                num_words=None,\n",
    "#                stopwords=[],\n",
    "#                labeldict={},\n",
    "#                bos=None,\n",
    "#                eos=None):\n",
    "#     if not os.path.exists(targetdir): os.mkdir(targetdir)\n",
    "#\n",
    "#     #获取数据集\n",
    "#     train_file = \"\"\n",
    "#     dev_file = \"\"\n",
    "#     test_file = \"\"\n",
    "#     for file in os.listdir(inputdir):\n",
    "#         if fnmatch.fnmatch(file,\"*_train.txt\"):\n",
    "#             train_file = file\n",
    "#         elif fnmatch.fnmatch(file,\"*_dev.txt\"):\n",
    "#             dev_file = file\n",
    "#         elif fnmatch.fnmatch(file,\"*_test.txt\"):\n",
    "#             test_file = file\n",
    "#\n",
    "#     #数据预处理\n",
    "#     preprocessor = Preprocessor(lowercase=lowercase,\n",
    "#                                 ignore_punctuation=ignore_punctuation,\n",
    "#                                 num_words=num_words,\n",
    "#                                 stopwords=stopwords,\n",
    "#                                 labeldict=labeldict,\n",
    "#                                 bos=bos,\n",
    "#                                 eos=eos)\n",
    "#     print(\"=============训练数据预处理中=================\")\n",
    "#     print(\"读取数据\")\n",
    "#     data = preprocessor.read_data(os.path.join(inputdir,train_file))\n",
    "#     print(\"计算词向量\")\n",
    "#     preprocessor.build_worddict(data)\n",
    "#     with open(os.path.join(targetdir,\"worddict.pkl\"),\"wb\") as pkl_file:\n",
    "#         pickle.dump(preprocessor.worddict,pkl_file)\n",
    "#     print(\"词向量转换\")\n",
    "#     transformed_data = preprocessor.transform_to_indices(data)\n",
    "#     with open(os.path.join(targetdir,\"train_data.pkl\"),\"wb\") as pkl_file:\n",
    "#         pickle.dump(transformed_data,pkl_file)\n",
    "#\n",
    "#     print(\"============验证集预处理中===================\")\n",
    "#     print(\"读取数据\")\n",
    "#     data = preprocessor.read_data(os.path.join(inputdir,dev_file))\n",
    "#     print(\"词向量转换\")\n",
    "#     transformed_data = preprocessor.transform_to_indices(data)\n",
    "#     with open(os.path.join(targetdir,\"dev_data.pkl\"),\"wb\") as pkl_file:\n",
    "#         pickle.dump(transformed_data,pkl_file)\n",
    "#\n",
    "#     print(\"===========测试集预处理中=================\")\n",
    "#     print(\"读取数据\")\n",
    "#     data = preprocessor.read_data(os.path.join(inputdir,test_file))\n",
    "#     print(\"词向量转换\")\n",
    "#     transformed_data = preprocessor.transform_to_indices(data)\n",
    "#     with open(os.path.join(targetdir,\"test_data.pkl\"),\"wb\") as pkl_file:\n",
    "#         pickle.dump(transformed_data,pkl_file)\n",
    "#\n",
    "#     print(\"===========embedding预处理============\")\n",
    "#     embed_matrix = preprocessor.build_embedding_matrix(embeddings_file)\n",
    "#     with open(os.path.join(targetdir,\"embeddings.pkl\"),\"wb\") as pkl_file:\n",
    "#         pickle.dump(embed_matrix, pkl_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# #数据预处理\n",
    "# with open('preprocess.json','r') as f:\n",
    "#     pre_config = json.load(f)\n",
    "#\n",
    "# pre_args = argparse.Namespace(**pre_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# preprocess(inputdir=pre_args.data_dir,\n",
    "#            embeddings_file=pre_args.embeddings_file,\n",
    "#            targetdir=pre_args.target_dir,\n",
    "#            lowercase=pre_args.lowercase,\n",
    "#            num_words=pre_args.num_words,\n",
    "#            stopwords=pre_args.stopwords,\n",
    "#            labeldict=pre_args.labeldict,\n",
    "#            bos=pre_args.bos,\n",
    "#            eos=pre_args.eos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#数据训练\n",
    "with open(\"./train.json\",\"r\") as f:\n",
    "    train_config = json.load(f)\n",
    "\n",
    "train_args = argparse.Namespace(**train_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  Preparing for training  ====================\n",
      "\t* 加载训练数据...\n",
      "\t* 加载验证集...\n",
      "\t* 构建模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Codes\\python\\nlpbeginner\\task3-text-matching\\Utils.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 1.0983, accuracy: 34.3325%\n",
      "\n",
      " ==================== Training ESIM model on device: cuda:0 ====================\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0578s, loss: 0.6939: 100%|██████████| 17168/17168 [18:42<00:00, 15.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1122.9085s, loss = 0.6939, accuracy: 70.2894%\n",
      "* Validation for epoch 1:\n",
      "-> Valid. time: 4.7830s, loss: 0.4775, accuracy: 81.5586%\n",
      "\n",
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0577s, loss: 0.5226: 100%|██████████| 17168/17168 [18:39<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1119.7697s, loss = 0.5226, accuracy: 79.4043%\n",
      "* Validation for epoch 2:\n",
      "-> Valid. time: 4.5970s, loss: 0.4099, accuracy: 84.1292%\n",
      "\n",
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0586s, loss: 0.4740: 100%|██████████| 17168/17168 [18:55<00:00, 15.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1135.3000s, loss = 0.4740, accuracy: 81.6414%\n",
      "* Validation for epoch 3:\n",
      "-> Valid. time: 4.7030s, loss: 0.3915, accuracy: 84.9319%\n",
      "\n",
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0592s, loss: 0.4448: 100%|██████████| 17168/17168 [19:07<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1147.9577s, loss = 0.4448, accuracy: 82.9209%\n",
      "* Validation for epoch 4:\n",
      "-> Valid. time: 4.7760s, loss: 0.3833, accuracy: 85.5111%\n",
      "\n",
      "* Training epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0590s, loss: 0.4231:  38%|███▊      | 6564/17168 [07:18<11:52, 14.89it/s]"
     ]
    }
   ],
   "source": [
    "# run_train(train_file=train_args.train_data,\n",
    "#           valid_file=train_args.valid_data,\n",
    "#           embeddings_file=train_args.embeddings,\n",
    "#           target_dir=train_args.target_dir,\n",
    "#           hidden_size=train_args.hidden_size,\n",
    "#           dropout=train_args.dropout,\n",
    "#           num_classes=train_args.num_classes,\n",
    "#           epochs=train_args.epochs,\n",
    "#           batch_size=train_args.batch_size,\n",
    "#           lr=train_args.lr,\n",
    "#           patience=train_args.patience,\n",
    "#           max_grad_norm=train_args.max_gradient_norm,\n",
    "#           )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  Preparing for training  ====================\n",
      "\t* 加载训练数据...\n",
      "\t* 加载验证集...\n",
      "\t* 构建模型...\n",
      "\t* Training will continue on existing model from epoch 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Codes\\python\\nlpbeginner\\task3-text-matching\\Utils.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 0.3571, accuracy: 86.5881%\n",
      "\n",
      " ==================== Training ESIM model on device: cuda:0 ====================\n",
      "* Training epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0573s, loss: 0.3432: 100%|██████████| 17168/17168 [18:40<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1120.1519s, loss = 0.3432, accuracy: 87.2865%\n",
      "* Validation for epoch 11:\n",
      "-> Valid. time: 4.9919s, loss: 0.3572, accuracy: 86.6694%\n",
      "\n",
      "* Training epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0588s, loss: 0.3409: 100%|██████████| 17168/17168 [19:06<00:00, 14.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1146.1898s, loss = 0.3409, accuracy: 87.3917%\n",
      "* Validation for epoch 12:\n",
      "-> Valid. time: 4.7640s, loss: 0.3553, accuracy: 86.6491%\n",
      "\n",
      "* Training epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0590s, loss: 0.3384: 100%|██████████| 17168/17168 [19:06<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 1146.8215s, loss = 0.3384, accuracy: 87.4621%\n",
      "* Validation for epoch 13:\n",
      "-> Valid. time: 4.9530s, loss: 0.3554, accuracy: 86.7100%\n",
      "\n",
      "* Training epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0590s, loss: 0.3388:  55%|█████▌    | 9469/17168 [10:32<08:17, 15.46it/s]"
     ]
    }
   ],
   "source": [
    "run_train(train_file=train_args.train_data,\n",
    "          valid_file=train_args.valid_data,\n",
    "          embeddings_file=train_args.embeddings,\n",
    "          target_dir=train_args.target_dir,\n",
    "          hidden_size=train_args.hidden_size,\n",
    "          dropout=train_args.dropout,\n",
    "          num_classes=train_args.num_classes,\n",
    "          epochs=train_args.epochs,\n",
    "          batch_size=train_args.batch_size,\n",
    "          lr=train_args.lr,\n",
    "          patience=train_args.patience,\n",
    "          max_grad_norm=train_args.max_gradient_norm,\n",
    "          checkpoint=\"./checkpoints/esim_10.pth.tar\"\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# jupyter notebook训练4~5轮后不继续显示数据信息，换python脚本训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}