{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE.type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "BATCH_SIZE=10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(\"../data/sentiment-analysis-on-movie-reviews/train.tsv\",delimiter='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data,test_data = train_test_split(data_all,test_size=0.2,random_state=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data.to_csv('../data/task2/train.csv',index=False)\n",
    "test_data.to_csv('../data/task2/test.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "PAD_TOKEN='<pad>'\n",
    "TEXT = data.Field(sequential=True,batch_first=True, lower=True, pad_token=PAD_TOKEN)\n",
    "LABEL = data.Field(sequential=False, batch_first=True, unk_token=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "datafields = [(\"PhraseId\", None), # 不需要的filed设置为None\n",
    "              (\"SentenceId\", None),\n",
    "              ('Phrase', TEXT),\n",
    "              ('Sentiment', LABEL)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_data = data.TabularDataset(path='../data/task2/train.csv',format='csv',fields=datafields)\n",
    "test_data = data.TabularDataset(path='../data/task2/test.csv',format='csv',fields=datafields)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [09:46, 1.47MB/s]                                \n",
      "100%|█████████▉| 399999/400000 [00:18<00:00, 21523.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#构建词典，字符映射到embedding\n",
    "#TEXT.vocab.vectors 就是词向量\n",
    "TEXT.build_vocab(train_data,  vectors= 'glove.6B.50d',\n",
    "                 unk_init= lambda x:torch.nn.init.uniform_(x, a=-0.25, b=0.25))\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "\n",
    "#得到索引，PAD_TOKEN='<pad>'\n",
    "PAD_INDEX = TEXT.vocab.stoi[PAD_TOKEN]\n",
    "TEXT.vocab.vectors[PAD_INDEX] = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#构建迭代器\n",
    "train_iterator = data.BucketIterator(train_data, batch_size=BATCH_SIZE,train=True, shuffle=True,device=DEVICE)\n",
    "\n",
    "test_iterator = data.Iterator(test_data, batch_size=len(test_data),train=False,sort=False, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16517 6\n"
     ]
    }
   ],
   "source": [
    "#部分参数设置\n",
    "embedding_choice='glove'   #  'static'    'non-static'\n",
    "num_embeddings = len(TEXT.vocab)\n",
    "embedding_dim =50\n",
    "dropout_p=0.5\n",
    "filters_num=100\n",
    "\n",
    "vocab_size=len(TEXT.vocab)\n",
    "label_num=len(LABEL.vocab)\n",
    "print(vocab_size,label_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.embedding_choice=embedding_choice\n",
    "\n",
    "        if self.embedding_choice==  'rand':\n",
    "            self.embedding=nn.Embedding(num_embeddings,embedding_dim)\n",
    "        if self.embedding_choice==  'glove':\n",
    "            self.embedding = nn.Embedding(num_embeddings, embedding_dim,\n",
    "                padding_idx=PAD_INDEX).from_pretrained(TEXT.vocab.vectors, freeze=True)\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=filters_num ,  #卷积产生的通道\n",
    "                               kernel_size=(3, embedding_dim), padding=(2,0))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=1,out_channels=filters_num ,  #卷积产生的通道\n",
    "                               kernel_size=(4, embedding_dim), padding=(3,0))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=1,out_channels=filters_num ,  #卷积产生的通道\n",
    "                               kernel_size=(5, embedding_dim), padding=(4,0))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.fc = nn.Linear(filters_num * 3, label_num)\n",
    "\n",
    "    def forward(self,x):      # (Batch_size, Length)\n",
    "        x=self.embedding(x).unsqueeze(1)      #(Batch_size, Length, Dimention)\n",
    "                                       #(Batch_size, 1, Length, Dimention)\n",
    "\n",
    "        x1 = F.relu(self.conv1(x)).squeeze(3)    #(Batch_size, filters_num, length+padding, 1)\n",
    "                                          #(Batch_size, filters_num, length+padding)\n",
    "        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)  #(Batch_size, filters_num, 1)\n",
    "                                               #(Batch_size, filters_num)\n",
    "\n",
    "        x2 = F.relu(self.conv2(x)).squeeze(3)\n",
    "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
    "\n",
    "        x3 = F.relu(self.conv3(x)).squeeze(3)\n",
    "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3), dim=1)  #(Batch_size, filters_num *3 )\n",
    "        x = self.dropout(x)      #(Batch_size, filters_num *3 )\n",
    "        out = self.fc(x)       #(Batch_size, label_num  )\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#构建模型\n",
    "\n",
    "model=CNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)#创建优化器SGD\n",
    "criterion = nn.CrossEntropyLoss()   #损失函数\n",
    "\n",
    "if DEVICE.type=='cuda':\n",
    "    model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0_0.801%:  Training average Loss: 1.025518\n",
      "Epoch 0_1.602%:  Training average Loss: 1.017275\n",
      "Epoch 0_2.403%:  Training average Loss: 1.032822\n",
      "Epoch 0_3.204%:  Training average Loss: 1.020456\n",
      "Epoch 0_4.005%:  Training average Loss: 1.007579\n",
      "Epoch 0_4.806%:  Training average Loss: 1.009438\n",
      "Epoch 0_5.607%:  Training average Loss: 1.005703\n",
      "Epoch 0_6.408%:  Training average Loss: 1.005773\n",
      "Epoch 0_7.209%:  Training average Loss: 1.004576\n",
      "Epoch 0_8.010%:  Training average Loss: 1.005422\n",
      "Epoch 0_8.811%:  Training average Loss: 1.011184\n",
      "Epoch 0_9.612%:  Training average Loss: 1.011259\n",
      "Epoch 0_10.413%:  Training average Loss: 1.011732\n",
      "Epoch 0_11.214%:  Training average Loss: 1.009617\n",
      "Epoch 0_12.015%:  Training average Loss: 1.008926\n",
      "Epoch 0_12.815%:  Training average Loss: 1.009234\n",
      "Epoch 0_13.616%:  Training average Loss: 1.011360\n",
      "Epoch 0_14.417%:  Training average Loss: 1.011482\n",
      "Epoch 0_15.218%:  Training average Loss: 1.011780\n",
      "Epoch 0_16.019%:  Training average Loss: 1.013563\n",
      "Epoch 0_16.820%:  Training average Loss: 1.012013\n",
      "Epoch 0_17.621%:  Training average Loss: 1.011835\n",
      "Epoch 0_18.422%:  Training average Loss: 1.012020\n",
      "Epoch 0_19.223%:  Training average Loss: 1.012162\n",
      "Epoch 0_20.024%:  Training average Loss: 1.012288\n",
      "Epoch 0_20.825%:  Training average Loss: 1.011321\n",
      "Epoch 0_21.626%:  Training average Loss: 1.009199\n",
      "Epoch 0_22.427%:  Training average Loss: 1.009462\n",
      "Epoch 0_23.228%:  Training average Loss: 1.009626\n",
      "Epoch 0_24.029%:  Training average Loss: 1.009813\n",
      "Epoch 0_24.830%:  Training average Loss: 1.011071\n",
      "Epoch 0_25.631%:  Training average Loss: 1.011743\n",
      "Epoch 0_26.432%:  Training average Loss: 1.012122\n",
      "Epoch 0_27.233%:  Training average Loss: 1.011388\n",
      "Epoch 0_28.034%:  Training average Loss: 1.010269\n",
      "Epoch 0_28.835%:  Training average Loss: 1.009747\n",
      "Epoch 0_29.636%:  Training average Loss: 1.012529\n",
      "Epoch 0_30.437%:  Training average Loss: 1.013348\n",
      "Epoch 0_31.238%:  Training average Loss: 1.011611\n",
      "Epoch 0_32.039%:  Training average Loss: 1.011573\n",
      "Epoch 0_32.840%:  Training average Loss: 1.011218\n",
      "Epoch 0_33.641%:  Training average Loss: 1.011277\n",
      "Epoch 0_34.442%:  Training average Loss: 1.011186\n",
      "Epoch 0_35.243%:  Training average Loss: 1.010997\n",
      "Epoch 0_36.044%:  Training average Loss: 1.010783\n",
      "Epoch 0_36.845%:  Training average Loss: 1.010350\n",
      "Epoch 0_37.645%:  Training average Loss: 1.009469\n",
      "Epoch 0_38.446%:  Training average Loss: 1.010020\n",
      "Epoch 0_39.247%:  Training average Loss: 1.009842\n",
      "Epoch 0_40.048%:  Training average Loss: 1.009823\n",
      "Epoch 0_40.849%:  Training average Loss: 1.010304\n",
      "Epoch 0_41.650%:  Training average Loss: 1.010564\n",
      "Epoch 0_42.451%:  Training average Loss: 1.010172\n",
      "Epoch 0_43.252%:  Training average Loss: 1.010082\n",
      "Epoch 0_44.053%:  Training average Loss: 1.010304\n",
      "Epoch 0_44.854%:  Training average Loss: 1.010411\n",
      "Epoch 0_45.655%:  Training average Loss: 1.010610\n",
      "Epoch 0_46.456%:  Training average Loss: 1.010511\n",
      "Epoch 0_47.257%:  Training average Loss: 1.011000\n",
      "Epoch 0_48.058%:  Training average Loss: 1.010578\n",
      "Epoch 0_48.859%:  Training average Loss: 1.010344\n",
      "Epoch 0_49.660%:  Training average Loss: 1.010773\n",
      "Epoch 0_50.461%:  Training average Loss: 1.010624\n",
      "Epoch 0_51.262%:  Training average Loss: 1.010575\n",
      "Epoch 0_52.063%:  Training average Loss: 1.010269\n",
      "Epoch 0_52.864%:  Training average Loss: 1.010812\n",
      "Epoch 0_53.665%:  Training average Loss: 1.011374\n",
      "Epoch 0_54.466%:  Training average Loss: 1.011250\n",
      "Epoch 0_55.267%:  Training average Loss: 1.010715\n",
      "Epoch 0_56.068%:  Training average Loss: 1.010719\n",
      "Epoch 0_56.869%:  Training average Loss: 1.010667\n",
      "Epoch 0_57.670%:  Training average Loss: 1.011081\n",
      "Epoch 0_58.471%:  Training average Loss: 1.011192\n",
      "Epoch 0_59.272%:  Training average Loss: 1.011724\n",
      "Epoch 0_60.073%:  Training average Loss: 1.011408\n",
      "Epoch 0_60.874%:  Training average Loss: 1.010997\n",
      "Epoch 0_61.675%:  Training average Loss: 1.010609\n",
      "Epoch 0_62.475%:  Training average Loss: 1.010061\n",
      "Epoch 0_63.276%:  Training average Loss: 1.009557\n",
      "Epoch 0_64.077%:  Training average Loss: 1.009559\n",
      "Epoch 0_64.878%:  Training average Loss: 1.009917\n",
      "Epoch 0_65.679%:  Training average Loss: 1.009714\n",
      "Epoch 0_66.480%:  Training average Loss: 1.009813\n",
      "Epoch 0_67.281%:  Training average Loss: 1.010337\n",
      "Epoch 0_68.082%:  Training average Loss: 1.010363\n",
      "Epoch 0_68.883%:  Training average Loss: 1.010057\n",
      "Epoch 0_69.684%:  Training average Loss: 1.009600\n",
      "Epoch 0_70.485%:  Training average Loss: 1.009615\n",
      "Epoch 0_71.286%:  Training average Loss: 1.009776\n",
      "Epoch 0_72.087%:  Training average Loss: 1.009737\n",
      "Epoch 0_72.888%:  Training average Loss: 1.009923\n",
      "Epoch 0_73.689%:  Training average Loss: 1.009909\n",
      "Epoch 0_74.490%:  Training average Loss: 1.009698\n",
      "Epoch 0_75.291%:  Training average Loss: 1.010261\n",
      "Epoch 0_76.092%:  Training average Loss: 1.009957\n",
      "Epoch 0_76.893%:  Training average Loss: 1.010360\n",
      "Epoch 0_77.694%:  Training average Loss: 1.010529\n",
      "Epoch 0_78.495%:  Training average Loss: 1.010785\n",
      "Epoch 0_79.296%:  Training average Loss: 1.010427\n",
      "Epoch 0_80.097%:  Training average Loss: 1.010181\n",
      "Epoch 0_80.898%:  Training average Loss: 1.010291\n",
      "Epoch 0_81.699%:  Training average Loss: 1.009906\n",
      "Epoch 0_82.500%:  Training average Loss: 1.009860\n",
      "Epoch 0_83.301%:  Training average Loss: 1.009622\n",
      "Epoch 0_84.102%:  Training average Loss: 1.009742\n",
      "Epoch 0_84.903%:  Training average Loss: 1.009371\n",
      "Epoch 0_85.704%:  Training average Loss: 1.009092\n",
      "Epoch 0_86.504%:  Training average Loss: 1.008940\n",
      "Epoch 0_87.305%:  Training average Loss: 1.008827\n",
      "Epoch 0_88.106%:  Training average Loss: 1.008405\n",
      "Epoch 0_88.907%:  Training average Loss: 1.008256\n",
      "Epoch 0_89.708%:  Training average Loss: 1.007728\n",
      "Epoch 0_90.509%:  Training average Loss: 1.007940\n",
      "Epoch 0_91.310%:  Training average Loss: 1.007891\n",
      "Epoch 0_92.111%:  Training average Loss: 1.008099\n",
      "Epoch 0_92.912%:  Training average Loss: 1.007882\n",
      "Epoch 0_93.713%:  Training average Loss: 1.007906\n",
      "Epoch 0_94.514%:  Training average Loss: 1.007542\n",
      "Epoch 0_95.315%:  Training average Loss: 1.007517\n",
      "Epoch 0_96.116%:  Training average Loss: 1.007280\n",
      "Epoch 0_96.917%:  Training average Loss: 1.007368\n",
      "Epoch 0_97.718%:  Training average Loss: 1.007401\n",
      "Epoch 0_98.519%:  Training average Loss: 1.007028\n",
      "Epoch 0_99.320%:  Training average Loss: 1.006943\n",
      "Epoch 0 :  Verification average Loss: 0.963648, Verification accuracy: 60.391504%,Total Time:105.614999\n",
      "Model is saved in model_dict/model_glove/epoch_0_accuracy_0.603915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch102\\lib\\site-packages\\torch\\serialization.py:401: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "import time\n",
    "epoch=100\n",
    "best_accuracy=0.0\n",
    "start_time=time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    total_loss=0.0\n",
    "    accuracy=0.0\n",
    "    total_correct=0.0\n",
    "    total_data_num = len(train_iterator.dataset)\n",
    "    steps = 0.0\n",
    "    #训练\n",
    "    for batch in train_iterator:\n",
    "        steps+=1\n",
    "        #print(steps)\n",
    "        optimizer.zero_grad() #  梯度缓存清零\n",
    "\n",
    "        batch_text=batch.Phrase\n",
    "        batch_label=batch.Sentiment\n",
    "        out=model(batch_text)    #[batch_size, label_num]\n",
    "        loss = criterion(out, batch_label)\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (torch.max(out, dim=1)[1]  #get the indices\n",
    "                   .view(batch_label.size()) == batch_label).sum()\n",
    "        total_correct = total_correct + correct.item()\n",
    "\n",
    "        if steps%100==0:\n",
    "            print(\"Epoch %d_%.3f%%:  Training average Loss: %f\"\n",
    "                      %(i, steps * train_iterator.batch_size*100/len(train_iterator.dataset),total_loss/steps))\n",
    "\n",
    "    #每个epoch都验证一下\n",
    "    model.eval()\n",
    "    total_loss=0.0\n",
    "    accuracy=0.0\n",
    "    total_correct=0.0\n",
    "    total_data_num = len(test_iterator.dataset)\n",
    "    steps = 0.0\n",
    "    for batch in test_iterator:\n",
    "        steps+=1\n",
    "        batch_text=batch.Phrase\n",
    "        batch_label=batch.Sentiment\n",
    "        out=model(batch_text)\n",
    "        loss = criterion(out, batch_label)\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        correct = (torch.max(out, dim=1)[1].view(batch_label.size()) == batch_label).sum()\n",
    "        total_correct = total_correct + correct.item()\n",
    "\n",
    "        print(\"Epoch %d :  Verification average Loss: %f, Verification accuracy: %f%%,Total Time:%f\"\n",
    "          %(i, total_loss/steps, total_correct*100/total_data_num,time.time()-start_time))\n",
    "\n",
    "        if best_accuracy < total_correct/total_data_num :\n",
    "            best_accuracy =total_correct/total_data_num\n",
    "            torch.save(model,'model_dict/model_glove/epoch_%d_accuracy_%f'%(i,total_correct/total_data_num))\n",
    "            print('Model is saved in model_dict/model_glove/epoch_%d_accuracy_%f'%(i,total_correct/total_data_num))\n",
    "            #torch.cuda.empty_cache()\n",
    "    break #运行时去除break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}